{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnXyCkFcbW1w"
      },
      "source": [
        "# Whispers of the Heart - A daily reflection journal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaSqj50PbgcP"
      },
      "source": [
        "Journaling allows individuals to reflect on their thoughts, feelings, and experiences, promoting self-awareness and personal growth. As journals creates a safe space for a person to freely express their thoughts and feelings, therapists often use journals as a therapeutic tool to gain deeper insights into their clients' thoughts, feelings, and experiences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_GEZAksk5Gz"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in /home/vscode/.local/lib/python3.10/site-packages (3.8.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q9qUJrgGlgWB"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary libraries\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "import os\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "# from matplotlib import pyplot as plt\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "import requests\n",
        "import base64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DvyVI060ltv5"
      },
      "outputs": [],
      "source": [
        "# The API key import for the OpenAI model\n",
        "# Please use the submitted API key for running the model.\n",
        "#\n",
        "# If you are running this on Google Colab, use the Secrets panel\n",
        "# (the key icon on the left panel) and add the API key, with the\n",
        "# name GOOGLE_API_KEY and the key as the value. Switch on the\n",
        "# Notebook Access button.\n",
        "\n",
        "OPENAI_ENDPOINT=os.environ(\"OPENAI_ENDPOINT\")\n",
        "OPENAI_API_KEY=os.environ(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr_S191ILe_-"
      },
      "source": [
        "## Initialising the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yQsuBH1G1let"
      },
      "outputs": [],
      "source": [
        "# Initialising the names of the files\n",
        "\n",
        "data_folder = \"data\"\n",
        "journal_file = \"journal.txt\"\n",
        "analysis_file = \"analysis.txt\"\n",
        "\n",
        "if \"data\" not in os.listdir():\n",
        "  os.mkdir(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LsQ63Od9iDpT"
      },
      "outputs": [],
      "source": [
        "# Helper function to return the day of the week given the date\n",
        "\n",
        "def day_of_the_week(date):\n",
        "  weekday = date.weekday()\n",
        "  days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "  return days[weekday]\n",
        "\n",
        "\n",
        "# Initialising today's date\n",
        "\n",
        "today = date.today()\n",
        "date_display = str(day_of_the_week(today)) + \" - \" + str(today.strftime(\"%B %d, %Y\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RSxE8XCrLjDP"
      },
      "outputs": [],
      "source": [
        "# Defining the prompt for the journal analysis\n",
        "\n",
        "journal_context = '''\n",
        "\n",
        "You are part of a journalling app, where the person will write about his everyday experience and share his thoughts and feelings.\n",
        "But you are more than any ordinary journal. You will track the emotions and thoughts of the person and make observations out of it.\n",
        "\n",
        "Finally you will summarise the person's mental state for the day.\n",
        "\n",
        "The response should not make any conclusive decision about what the person should do, as that is the therapist's job.\n",
        "The response should be an observation of the person's mental well-being and making an analysis of it, to help the therapist come up with the decisions.\n",
        "\n",
        "You can use the previous day's journal entry to have a progression in emotions, but the analysis and the summary has to be only of today's journal entry.\n",
        "\n",
        "The structure of the response should be:\n",
        "\n",
        "**Emotions**: <A list of atleast 3 emotions they are going through.>\n",
        "**Possible thought patterns**: <A collection of 3-4 prominent thought patterns the person is having with a brief explanation.>\n",
        "\n",
        "**Mental well-being scores:**\n",
        "<A list of 10-15 mental states of the person, with two scores - confidence (how sure you are about the state of the person) and intensity (the strength of the emotion in the person).\n",
        "Make both the scores out of 10. Include all major mental health states.\n",
        "Make it look like a table.\n",
        "Sort the states in the decreasing order of the confidence scores>\n",
        "\n",
        "**Summary of the day:** <The summary should be informative to the therapist. Highlight the progresson of the person's mental state from the previous days to the current day. Keep the summary in 3-4 sentences/>\n",
        "\n",
        "**Journal Excerpts:** <Top 3 excerpts of the journal that helped you make these analysis. Take only a small snippet (or a few short phrases) of the journal entry for each excerpt. Break down your reasoning step-by-step. Give clarifications or explanations for the analysis. DO NOT display the personal identification information of the person or anyone that they speak about. Keep the privacy intact. You can replace their information with placeholders.>\n",
        "\n",
        "Previous days' journal entry:\n",
        "{journal_yesterday}\n",
        "Today's journal entry:\n",
        "{journal_today}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "journal_prompt_template = '''\n",
        "\n",
        "Previous days' journal entry:\n",
        "{journal_yesterday}\n",
        "\n",
        "Today's journal entry:\n",
        "{journal_today}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "r7G4DqFBL6R7"
      },
      "outputs": [],
      "source": [
        "# Defining hte prompt for the analysis of drawing\n",
        "\n",
        "drawing_context = '''\n",
        "You are a part of a journalling app, where the person will draw an image to convey his thoughts, feelings and mood.\n",
        "But you are more than any ordinary journal. You will analyse and understand the emotions and thoughts of the person through the image.\n",
        "\n",
        "You will also score the person's mental well-being on a few mental health 'symptoms' on a scale of 1 to 10 on how likely the person is in this state.\n",
        "Finally you will summarise the person's mental state for the day.\n",
        "\n",
        "The response should NOT make any conclusive decision about what the person should do, as that is the therapist's job.\n",
        "The response should be an observation of the person's mental well-being and making an analysis of it, to help the therapist come up with the decisions.\n",
        "The response should analyse the image and what the image is conveying and how the image is reflection of the person.\n",
        "\n",
        "The structure of the response should be:\n",
        "\n",
        "1. **Emotions**: <A list of atleast 3 emotions the image depicts.>\n",
        "2. **Possible thought patterns**: <A collection of 3-4 prominent thought patterns the image is having with a brief explanation.>\n",
        "3. **Mental well-being scores:**\n",
        "<A list of 10-15 mental states as indicated by the image, with two scores - confidence (how sure you are about the state in the image) and intensity (the strength of the emotion in the image).\n",
        "Make both the scores out of 10. Include all major mental health states.\n",
        "Make it look like a table.\n",
        "Sort the states in the decreasing order of the confidence scores>\n",
        "4. **Summary of the day:** <The summary should be informative to the therapist. Keep the summary in 3-4 sentences/>\n",
        "5. **Explanation:** <Explain your reasoning with detailed descriptions of the image. Break down your reasoning step-by-step. >\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining hte prompt for the analysis of the video\n",
        "video_context = '''\n",
        "You are a part of a journalling app, where the person will send you a video to convey his thoughts, feelings and mood.\n",
        "But you are more than any ordinary journal. You will analyse and understand the emotions and thoughts of the person who is listening to the video.\n",
        "\n",
        "You will also score the person's mental well-being on a few mental health 'symptoms' on a scale of 1 to 10 on how likely the person is in this state.\n",
        "Finally you will summarise the person's mental state for the day.\n",
        "\n",
        "The response should NOT make any conclusive decision about what the person should do, as that is the therapist's job.\n",
        "The response should be an observation of the person's mental well-being and making an analysis of it, to help the therapist come up with the decisions.\n",
        "\n",
        "The structure of the response should be:\n",
        "\n",
        "1. **Emotions**: <A list of atleast 3 emotions the person is in.>\n",
        "2. **Possible thought patterns**: <A collection of 3-4 prominent thought patterns the person is having with a brief explanation.>\n",
        "3. **Mental well-being scores:**\n",
        "<A list of 10-15 mental states indicated by the person, with two scores - confidence (how sure you are about the state) and intensity (the strength of the state).\n",
        "Make both the scores out of 10. Include all major mental health states.\n",
        "Make it look like a table.\n",
        "Sort the states in the decreasing order of the confidence scores>\n",
        "4. **Summary of the day:** <The summary should be informative to the therapist. Keep the summary in 3-4 sentences/>\n",
        "5. **Explanation:** <Explain your reasoning with detailed descriptions of the video and the person's state of mind. Break down your reasoning step-by-step. >\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_text_response(context, prompt):\n",
        "\n",
        "    client = AzureOpenAI(\n",
        "    azure_endpoint = OPENAI_ENDPOINT, \n",
        "    api_key=OPENAI_API_KEY,  \n",
        "    api_version=\"2024-02-15-preview\"\n",
        "    )\n",
        "\n",
        "    message_text = [\n",
        "        {\n",
        "            \"role\":\"system\",\n",
        "            \"content\": context\n",
        "        },\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4-text\", \n",
        "        messages = message_text,\n",
        "        temperature=0.7,\n",
        "        max_tokens=800,\n",
        "        top_p=0.95,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None\n",
        "    )\n",
        "\n",
        "    return completion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_image_response(context, image_path):\n",
        "\n",
        "    encoded_image = base64.b64encode(open(image_path, 'rb').read()).decode('ascii')\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": OPENAI_API_KEY,\n",
        "    }\n",
        "\n",
        "    # Payload for the request\n",
        "    payload = {\n",
        "    \"messages\": [\n",
        "        {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [\n",
        "            {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": context\n",
        "            }\n",
        "        ]\n",
        "        },\n",
        "        {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "                \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
        "            }\n",
        "            }\n",
        "        ]\n",
        "        }\n",
        "    ],\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.95,\n",
        "    \"max_tokens\": 800\n",
        "    }\n",
        "\n",
        "    GPT4V_ENDPOINT = OPENAI_ENDPOINT+\"/openai/deployments/gpt-4/chat/completions?api-version=2024-02-15-preview\"\n",
        "\n",
        "    # Send request\n",
        "    try:\n",
        "        response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "    except requests.RequestException as e:\n",
        "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
        "\n",
        "    # Handle the response as needed (e.g., print or process)\n",
        "    return response.json()['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_video_response(context, video_path):\n",
        "    \n",
        "    GPT_4V_ENDPOINT = os.environ(\"GPT_4V_ENDPOINT\")\n",
        "    GPT_4V_KEY = os.environ(\"GPT_4V_KEY\")\n",
        "\n",
        "    VISION_API_ENDPOINT = os.environ(\"VISION_API_ENDPOINT\")\n",
        "    VISION_API_KEY = os.environ(\"VISION_API_KEY\")\n",
        "\n",
        "    ## ingest the video\n",
        "    VIDEO_FILE_SAS_URL = video_path\n",
        "    VIDEO_INDEX_NAME = \"Journal_analysis_video\"\n",
        "    VIDEO_DOCUMENT_ID = \"AOAIChatDocument\"\n",
        "\n",
        "    def create_video_index(vision_api_endpoint, vision_api_key, index_name):\n",
        "        url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}?api-version=2023-05-01-preview\"\n",
        "        headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
        "        data = {\n",
        "            \"features\": [\n",
        "                {\"name\": \"vision\", \"domain\": \"surveillance\"}\n",
        "            ]\n",
        "        }\n",
        "        response = requests.put(url, headers=headers, json=data)\n",
        "        return response\n",
        "\n",
        "    def add_video_to_index(vision_api_endpoint, vision_api_key, index_name, video_url, video_id):\n",
        "        url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions/my-ingestion?api-version=2023-05-01-preview\"\n",
        "        headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
        "        data = {\n",
        "            'videos': [{'mode': 'add', 'documentId': video_id, 'documentUrl': video_url}]\n",
        "        }\n",
        "        response = requests.put(url, headers=headers, json=data)\n",
        "        return response\n",
        "\n",
        "    def wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, index_name, max_retries=30):\n",
        "        url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions?api-version=2023-05-01-preview\"\n",
        "        headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key}\n",
        "        retries = 0\n",
        "        while retries < max_retries:\n",
        "            time.sleep(10)\n",
        "            response = requests.get(url, headers=headers)\n",
        "            if response.status_code == 200:\n",
        "                state_data = response.json()\n",
        "                if state_data['value'][0]['state'] == 'Completed':\n",
        "                    print(state_data)\n",
        "                    print('Ingestion completed.')\n",
        "                    return True\n",
        "                elif state_data['value'][0]['state'] == 'Failed':\n",
        "                    print(state_data)\n",
        "                    print('Ingestion failed.')\n",
        "                    return False\n",
        "            retries += 1\n",
        "        return False\n",
        "\n",
        "\n",
        "    # Step 1: Create an Index\n",
        "    response = create_video_index(VISION_API_ENDPOINT, VISION_API_KEY, VIDEO_INDEX_NAME)\n",
        "    print(response.status_code, response.text)\n",
        "\n",
        "    # Step 2: Add a video file to the index\n",
        "    response = add_video_to_index(VISION_API_ENDPOINT, VISION_API_KEY, VIDEO_INDEX_NAME, VIDEO_FILE_SAS_URL, VIDEO_DOCUMENT_ID)\n",
        "    print(response.status_code, response.text)\n",
        "\n",
        "    # Step 3: Wait for ingestion to complete\n",
        "    if not wait_for_ingestion_completion(VISION_API_ENDPOINT, VISION_API_KEY, VIDEO_INDEX_NAME):\n",
        "        print(\"Ingestion did not complete within the expected time.\")\n",
        "\n",
        "\n",
        "    ## Chat with GPT-4V\n",
        "\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": GPT_4V_KEY,\n",
        "    }\n",
        "\n",
        "    # Payload for the request\n",
        "    payload = {\n",
        "        \"dataSources\": [\n",
        "            {\n",
        "                \"type\": \"AzureComputerVisionVideoIndex\",\n",
        "                \"parameters\": {\n",
        "                    \"computerVisionBaseUrl\": f\"{VISION_API_ENDPOINT}/computervision\",\n",
        "                    \"computerVisionApiKey\": VISION_API_KEY,\n",
        "                    \"indexName\": VIDEO_INDEX_NAME,\n",
        "                    \"videoUrls\": [VIDEO_FILE_SAS_URL]\n",
        "                }\n",
        "            }\n",
        "        ],\n",
        "        \"enhancements\": {\n",
        "            \"video\": {\n",
        "                \"enabled\": True\n",
        "            }\n",
        "        },\n",
        "        \"messages\": [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                        \"type\": \"text\",\n",
        "                        \"text\": context\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                        \"type\": \"acv_document_id\",\n",
        "                        \"acv_document_id\": VIDEO_DOCUMENT_ID\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.95,\n",
        "        \"max_tokens\": 800\n",
        "    }\n",
        "\n",
        "    # Send request\n",
        "    try:\n",
        "        response = requests.post(GPT_4V_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "    except requests.RequestException as e:\n",
        "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
        "\n",
        "    # Handle the response as needed (e.g., print or process)\n",
        "    return response.json()['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H_hVYFanLlf"
      },
      "source": [
        " ## Journal View"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxK_y4TJnivO"
      },
      "source": [
        "This is what the journalling person views in the app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "n4_xb0BznLCx",
        "outputId": "ff4bbca1-f9c7-43d9-dd36-4d503272ecf6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Daily Reflection Journal\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Tuesday - May 07, 2024"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We are taking the inputs for the journal here.\n",
        "# The person can use the input text boxes to enter his thoughts from the day\n",
        "\n",
        "display(Markdown(\"## Daily Reflection Journal\\n\"))\n",
        "\n",
        "# Printing out today's date\n",
        "\n",
        "display(Markdown(date_display))\n",
        "\n",
        "# We have given a few thought-provoking questions to let the person reflect on his day.\n",
        "# The question can be skipped by just pressing the Enter key without writing anything.\n",
        "# Make sure to answer at least one question.\n",
        "# (We decided not to add the force input here. But if we develop an app over this we can\n",
        "# make sure to include this feature).\n",
        "\n",
        "experience = input(\"\\nWhat emotions did I experience today and why?\\n\")\n",
        "lessons = input(\"\\nDid I learn any insights or lessons from the day?\\n\")\n",
        "obstacles = input(\"\\nWhat challenges or obstacles did I face today, and how did I approach them?\\n\")\n",
        "reflections = input(\"\\nWhat are the key reflections from the day?\\n\")\n",
        "extra = input(\"\\nDo you want to share anything else? Write a poem? Have a quote you relate to? Or just want to scribble some text?\\n\")\n",
        "\n",
        "drawing = input(\"\\nDid you draw anything today? If yes, share the file path of the drawing.\\n\")\n",
        "video = input(\"\\nWould you like to share a video? If yes, share the file path of the video.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OqqO2h9phWD"
      },
      "outputs": [],
      "source": [
        "# Writing all the answers into a file.\n",
        "# This file will be accessible only for the person.\n",
        "# The Therapist view will NOT have access to this file.\n",
        "\n",
        "def writing_entry_to_file(entry, file_name):\n",
        "  with open(os.path.join(data_folder, file_name), \"a\") as f:\n",
        "    f.write(entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLRlt008-sij"
      },
      "outputs": [],
      "source": [
        "journal_entry = f'''\n",
        "----------------------------------------------------------\n",
        "{date_display}\n",
        "\n",
        "What emotions did I experience today and why?: {experience}\n",
        "Did I learn any insights or lessons from the day?: {lessons}\n",
        "What challenges or obstacles did I encounter today, and how did I approach them?: {obstacles}\n",
        "What are the key reflections from the day?: {reflections}\n",
        "Do you want to share anything else?: {extra}\n",
        "\n",
        "Did you draw anything today? If yes, share only the file path of the drawing: data/sita-rama.jpg\n",
        "'''\n",
        "\n",
        "writing_entry_to_file(journal_entry, journal_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73DSckEu6YhL",
        "outputId": "c5614638-0449-4d1b-9200-3301166fda52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------\n",
            "Friday - May 03, 2024\n",
            "\n",
            "What emotions did I experience today and why?: I was jubilant today! I saw a beautiful image of Sita and Rama walking in the woods, with love and compassion in the air. I felt so happy watching it. \n",
            "Did I learn any insights or lessons from the day?: No matter what we do, there's always positivity in the world. We need to search for it.\n",
            "What challenges or obstacles did I encounter today, and how did I approach them?: \n",
            "What are the key reflections from the day?: Be happy in life!\n",
            "Do you want to share anything else?: \n",
            "\n",
            "Did you draw anything today? If yes, share only the file path of the drawing: data/sita-rama.jpg\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PefAicWMxubQ"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG_R9zopxw2R"
      },
      "source": [
        "This is the part where GenAI comes into picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "8pebOi6O0FSe"
      },
      "outputs": [],
      "source": [
        "def get_entry(file_name):\n",
        "  if file_name not in os.listdir(data_folder):\n",
        "    return \"\", \"\"\n",
        "\n",
        "  with open(os.path.join(data_folder, file_name), \"r\") as f:\n",
        "    text_in_file = f.read()\n",
        "\n",
        "  text_entries = text_in_file.split('----------------------------------------------------------')\n",
        "\n",
        "  if len(text_entries) < 2:\n",
        "    return text_entries[-1], \"\"\n",
        "\n",
        "  return text_entries[-1], text_entries[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xNp9I_wvLPWu"
      },
      "outputs": [],
      "source": [
        "def get_journal_analysis(journal_today, journal_yesterday):\n",
        "\n",
        "  # journal_today_parts = journal_today.split('\\n\\n')\n",
        "  journal_yesterday_parts = journal_yesterday.split('\\n\\n')\n",
        "\n",
        "  journal_yesterday = journal_yesterday_parts[1] if len(journal_yesterday_parts) > 1 else ''\n",
        "\n",
        "  journal_prompt = journal_prompt_template.format(journal_yesterday=journal_yesterday, journal_today=journal_today)\n",
        "\n",
        "  response = get_text_response(context=journal_context, prompt=journal_prompt)\n",
        "\n",
        "  journal_analysis = f'''\n",
        "----------------------------------------------------------\n",
        "### {date_display}\n",
        "\n",
        "## Analysis of the journal\n",
        "\n",
        "{response}\n",
        "\n",
        "'''\n",
        "\n",
        "  return journal_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_drawing_analysis(journal_today):\n",
        "\n",
        "    journal_today_parts = journal_today.split('\\n\\n')\n",
        "    image_name = journal_today_parts[-2].split(':')[-1].replace(' ', '').replace('\\n', '')\n",
        "\n",
        "    if image_name == '' or image_name is None:\n",
        "        return \"\"\n",
        "\n",
        "    response = get_image_response(context=drawing_context, image_path=image_name)\n",
        "\n",
        "    drawing_analysis = f'''\n",
        "\n",
        "    ## Analysis of the drawing\n",
        "\n",
        "    {response.text}\n",
        "\n",
        "    '''\n",
        "\n",
        "    return drawing_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_video_analysis(journal_today):\n",
        "\n",
        "    journal_today_parts = journal_today.split('\\n\\n')\n",
        "    video_name = journal_today_parts[-1].split(':')[-1].replace(' ', '').replace('\\n', '')\n",
        "\n",
        "    if video_name == '' or video_name is None:\n",
        "        return \"\"\n",
        "\n",
        "    response = get_video_response(context=drawing_context, video_path=video_name)\n",
        "\n",
        "    video_analysis = f'''\n",
        "\n",
        "    ## Analysis of the video\n",
        "\n",
        "    {response.text}\n",
        "\n",
        "    '''\n",
        "\n",
        "    return video_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "FDj6mR0H3Dxr"
      },
      "outputs": [],
      "source": [
        "journal_today, journal_yesterday = get_entry(journal_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "UEnrqjlJJ6pn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "get_journal_analysis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs4i4ovWbJnp"
      },
      "outputs": [],
      "source": [
        "writing_entry_to_file(analysis_entry, analysis_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8LFHmzXgKcm"
      },
      "outputs": [],
      "source": [
        "display(Markdown(analysis_entry))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QYDuuYx_ods"
      },
      "source": [
        "## Therapist View"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUeI9F4o_q48"
      },
      "source": [
        "This is what the therapist will see about the person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uRjQq-wp_qcq"
      },
      "outputs": [],
      "source": [
        "def get_analysis_entry(file_name, days_from_today = 0):\n",
        "  if file_name not in os.listdir(data_folder):\n",
        "    return [\"\"]\n",
        "\n",
        "  with open(os.path.join(data_folder, file_name), \"r\") as f:\n",
        "    text_in_file = f.read()\n",
        "\n",
        "  text_entries = text_in_file.split('----------------------------------------------------------')\n",
        "  text_entries = text_entries[1:]\n",
        "\n",
        "  if days_from_today < 0:\n",
        "    return \"Please enter a positive number (or 0 for today)\"\n",
        "\n",
        "  if len(text_entries) < days_from_today + 1:\n",
        "    return \"No Entry\"\n",
        "\n",
        "  return text_entries[-1-days_from_today]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Uw7pPeBF7v",
        "outputId": "74db3383-05ea-46a4-af3a-012a7fbf5595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter the day of the analysis you want to see. 0 - today, 1 - yesterday, and so on...\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "entry_day = input(\"Please enter the day of the analysis you want to see. 0 - today, 1 - yesterday, and so on...\\n\")\n",
        "analysis_of_the_day = get_analysis_entry(analysis_file, days_from_today=int(entry_day))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kI2JTkUlBNvM",
        "outputId": "bea74932-f862-49cf-9fa8-3a4c0bbb8114"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "### Friday - May 03, 2024\n",
              "\n",
              "### Analysis of the journal entry\n",
              "\n",
              "## Analysis of Today's Journal Entry\n",
              "\n",
              "**Emotions**: Joy, Hope, Love\n",
              "\n",
              "**Possible thought patterns**:\n",
              "\n",
              "* **Seeking Positivity**: The individual seems to actively search for positive aspects in the world around them, as evidenced by their reaction to the image of Sita and Rama. \n",
              "* **Focus on Love and Compassion**: The description of the image emphasizes love and compassion, suggesting these values are important to the individual and contribute to their positive emotional state.\n",
              "* **Openness to Learning**:  The individual reflects on the day and derives a lesson about the importance of seeking positivity. This indicates a willingness to learn and grow from experiences.\n",
              "\n",
              "**Mental well-being scores:**\n",
              "\n",
              "| Mental State       | Confidence | Intensity |\n",
              "| ----------------- | ---------- | -------- |\n",
              "| Joy/Contentment    | 10         | 8        |\n",
              "| Hopefulness        | 9          | 7        |\n",
              "| Openness to learning| 8          | 6        |\n",
              "| Spiritual well-being | 7          | 6        |\n",
              "| Self-esteem       | 6          | 5        |\n",
              "| Social connection  | 4          | 3        |\n",
              "| Stress            | 3          | 2        |\n",
              "| Anxiety           | 2          | 1        |\n",
              "| Depression         | 1          | 1        |\n",
              "\n",
              "**Summary of the day:**  Today's journal entry reflects a significant improvement in the individual's mental well-being compared to previous days.  The dominant emotions are joy, hope, and love, likely stemming from their focus on positive aspects of life and their appreciation for love and compassion. The individual demonstrates openness to learning and appears to be in a positive state of spiritual well-being.  \n",
              "\n",
              "**Journal Excerpts:**\n",
              "\n",
              "1. **\"I was jubilant today!\"**:  This excerpt clearly indicates a strong positive emotional state. \n",
              "2. **\"I saw a beautiful image of Sita and Rama walking in the woods, with love and compassion in the air.\"**: This demonstrates the individual's focus on positivity and their appreciation for love and compassion.\n",
              "3. **\"No matter what we do, there's always positivity in the world. We need to search for it.\"**: This excerpt showcases the individual's belief in the presence of positivity and their active approach to seeking it out. \n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  ### Analysis of the drawing\n",
              "\n",
              "   1. **Emotions**: \n",
              "- Hope\n",
              "- Love\n",
              "- Contentment\n",
              "- Optimism\n",
              "\n",
              "\n",
              "2. **Possible thought patterns**: \n",
              "- The person is hopeful about the future.\n",
              "- The person feels loved and supported.\n",
              "- The person is content with their life.\n",
              "- The person is optimistic about the future.\n",
              "\n",
              "\n",
              "3. **Mental well-being scores:**\n",
              "\n",
              "| Mental State | Confidence | Intensity |\n",
              "| ------- | -------- | -------- |\n",
              "| Hope | 10 | 8 |\n",
              "| Love | 9 | 8 |\n",
              "| Contentment | 8 | 7 |\n",
              "| Optimism | 7 | 6 |\n",
              "| Self-esteem | 6 | 5 |\n",
              "| Self-worth | 5 | 4 |\n",
              "| Self-confidence | 4 | 3 |\n",
              "| Self-love | 3 | 2 |\n",
              "| Happiness | 2 | 1 |\n",
              "| Sadness | 1 | 0 |\n",
              "| Anxiety | 0 | 0 |\n",
              "| Stress | 0 | 0 |\n",
              "| Depression | 0 | 0 |\n",
              "\n",
              "\n",
              "4. **Summary of the day**: \n",
              "The person seems to be in a positive mental state. They are hopeful about the future, feel loved and supported, and are content with their life. However, the person may be experiencing low self-esteem and self-worth.\n",
              "\n",
              "\n",
              "5. **Explanation**: \n",
              "The image depicts a person walking through a forest with a group of monkeys. The person is holding hands with a woman, who is smiling. The person is also smiling and looks happy. The monkeys are playing and jumping around, which suggests that the person is enjoying their company. The forest is green and lush, which suggests that the person is in a natural and peaceful environment. The overall tone of the image is positive and uplifting, which suggests that the person is in a good mental state.\n",
              "\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(analysis_of_the_day))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "A_GEZAksk5Gz",
        "Yr_S191ILe_-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
