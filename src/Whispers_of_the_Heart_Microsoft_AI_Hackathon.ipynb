{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnXyCkFcbW1w"
      },
      "source": [
        "# Whispers of the Heart - A daily reflection journal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaSqj50PbgcP"
      },
      "source": [
        "Journaling allows individuals to reflect on their thoughts, feelings, and experiences, promoting self-awareness and personal growth. As journals creates a safe space for a person to freely express their thoughts and feelings, therapists often use journals as a therapeutic tool to gain deeper insights into their clients' thoughts, feelings, and experiences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_GEZAksk5Gz"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (3.8.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: openai in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (1.26.0)\n",
            "Requirement already satisfied: requests in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (2.31.0)\n",
            "Requirement already satisfied: ipython in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (8.24.0)\n",
            "Requirement already satisfied: jupyter in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (1.0.0)\n",
            "Requirement already satisfied: python-dotenv in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (4.9.0.80)\n",
            "Collecting azure-storage-blob\n",
            "  Downloading azure_storage_blob-12.19.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting azure-identity\n",
            "  Downloading azure_identity-1.16.0-py3-none-any.whl.metadata (76 kB)\n",
            "     ---------------------------------------- 0.0/77.0 kB ? eta -:--:--\n",
            "     ---------------------------------------- 77.0/77.0 kB 2.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (4.3.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from requests) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: decorator in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (0.1.7)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (2.18.0)\n",
            "Requirement already satisfied: stack-data in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (0.6.3)\n",
            "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (5.14.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipython) (0.4.6)\n",
            "Requirement already satisfied: notebook in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter) (7.1.3)\n",
            "Requirement already satisfied: qtconsole in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter) (5.5.2)\n",
            "Requirement already satisfied: jupyter-console in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter) (6.6.3)\n",
            "Requirement already satisfied: nbconvert in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter) (7.16.4)\n",
            "Requirement already satisfied: ipykernel in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter) (6.29.4)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter) (8.1.2)\n",
            "Collecting azure-core<2.0.0,>=1.28.0 (from azure-storage-blob)\n",
            "  Downloading azure_core-1.30.1-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting cryptography>=2.1.4 (from azure-storage-blob)\n",
            "  Downloading cryptography-42.0.7-cp39-abi3-win_amd64.whl.metadata (5.4 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-storage-blob)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n",
            "Collecting msal>=1.24.0 (from azure-identity)\n",
            "  Downloading msal-1.28.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting msal-extensions>=0.3.0 (from azure-identity)\n",
            "  Downloading msal_extensions-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: six>=1.11.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from azure-core<2.0.0,>=1.28.0->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from cryptography>=2.1.4->azure-storage-blob) (1.16.0)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
            "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal>=1.24.0->azure-identity)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting portalocker<3,>=1.6 (from msal-extensions>=0.3.0->azure-identity)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: comm>=0.1.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (1.8.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (8.6.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (5.7.2)\n",
            "Requirement already satisfied: nest-asyncio in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (1.6.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (5.9.8)\n",
            "Requirement already satisfied: pyzmq>=24 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (26.0.3)\n",
            "Requirement already satisfied: tornado>=6.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipykernel->jupyter) (6.4)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipywidgets->jupyter) (4.0.10)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from ipywidgets->jupyter) (3.0.10)\n",
            "Requirement already satisfied: beautifulsoup4 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (0.7.1)\n",
            "Requirement already satisfied: jinja2>=3.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (3.1.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (2.1.5)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (0.10.0)\n",
            "Requirement already satisfied: nbformat>=5.7 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (5.10.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbconvert->jupyter) (1.3.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from notebook->jupyter) (2.14.0)\n",
            "Requirement already satisfied: jupyterlab-server<3,>=2.22.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from notebook->jupyter) (2.27.1)\n",
            "Requirement already satisfied: jupyterlab<4.2,>=4.1.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from notebook->jupyter) (4.1.8)\n",
            "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from notebook->jupyter) (0.2.4)\n",
            "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from qtconsole->jupyter) (2.4.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from stack-data->ipython) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from stack-data->ipython) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
            "Requirement already satisfied: webencodings in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob) (2.22)\n",
            "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.1)\n",
            "Requirement already satisfied: pywin32>=300 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (306)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (23.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.10.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.5.3)\n",
            "Requirement already satisfied: overrides>=5.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.20.0)\n",
            "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.13)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter) (1.8.0)\n",
            "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook->jupyter) (2.0.4)\n",
            "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyterlab<4.2,>=4.1.1->notebook->jupyter) (2.2.5)\n",
            "Requirement already satisfied: babel>=2.10 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2.15.0)\n",
            "Requirement already satisfied: json5>=0.9.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.9.25)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyterlab-server<3,>=2.22.1->notebook->jupyter) (4.22.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter) (2.19.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter) (2.5)\n",
            "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.22.1->notebook->jupyter) (0.18.1)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.0.7)\n",
            "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (6.0.1)\n",
            "Requirement already satisfied: rfc3339-validator in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (0.1.1)\n",
            "Requirement already satisfied: fqdn in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.5.1)\n",
            "Requirement already satisfied: isoduration in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.4)\n",
            "Requirement already satisfied: uri-template in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.13)\n",
            "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (1.3.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\rithh\\documents\\college studies\\extras\\hackathon\\microsoft\\.venv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter) (2.9.0.20240316)\n",
            "Downloading azure_storage_blob-12.19.1-py3-none-any.whl (394 kB)\n",
            "   ---------------------------------------- 0.0/394.5 kB ? eta -:--:--\n",
            "   ------------------------ --------------- 245.8/394.5 kB 5.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 394.5/394.5 kB 4.9 MB/s eta 0:00:00\n",
            "Downloading azure_identity-1.16.0-py3-none-any.whl (166 kB)\n",
            "   ---------------------------------------- 0.0/166.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 166.1/166.1 kB 9.7 MB/s eta 0:00:00\n",
            "Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
            "   ---------------------------------------- 0.0/193.4 kB ? eta -:--:--\n",
            "   ---------------------------------------- 193.4/193.4 kB 5.9 MB/s eta 0:00:00\n",
            "Downloading cryptography-42.0.7-cp39-abi3-win_amd64.whl (2.9 MB)\n",
            "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
            "   ----------- ---------------------------- 0.8/2.9 MB 17.6 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 1.4/2.9 MB 17.2 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 2.2/2.9 MB 17.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.9/2.9 MB 15.4 MB/s eta 0:00:00\n",
            "Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 41.7/41.7 kB 2.0 MB/s eta 0:00:00\n",
            "Downloading msal-1.28.0-py3-none-any.whl (102 kB)\n",
            "   ---------------------------------------- 0.0/102.2 kB ? eta -:--:--\n",
            "   ---------------------------------------- 102.2/102.2 kB 5.7 MB/s eta 0:00:00\n",
            "Downloading msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: PyJWT, portalocker, isodate, cryptography, azure-core, azure-storage-blob, msal, msal-extensions, azure-identity\n",
            "Successfully installed PyJWT-2.8.0 azure-core-1.30.1 azure-identity-1.16.0 azure-storage-blob-12.19.1 cryptography-42.0.7 isodate-0.6.1 msal-1.28.0 msal-extensions-1.1.0 portalocker-2.8.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Library installations\n",
        "\n",
        "%pip install matplotlib pandas numpy openai requests ipython jupyter python-dotenv opencv-python azure-storage-blob azure-identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loading the environment variables.\n",
        "# Please check the config.env file and add the values.\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv(dotenv_path=\"config.env\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q9qUJrgGlgWB"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "import os\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "from azure.storage.blob import BlobServiceClient, BlobSasPermissions, generate_blob_sas\n",
        "\n",
        "import requests\n",
        "import base64\n",
        "from datetime import datetime, timedelta, timezone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DvyVI060ltv5"
      },
      "outputs": [],
      "source": [
        "# The API key import for the OpenAI model\n",
        "\n",
        "OPENAI_ENDPOINT=os.getenv(\"OPENAI_ENDPOINT\")\n",
        "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr_S191ILe_-"
      },
      "source": [
        "## Initialising the variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "yQsuBH1G1let"
      },
      "outputs": [],
      "source": [
        "# Initialising the names of the files\n",
        "\n",
        "data_folder = \"data\"\n",
        "journal_file = \"journal.txt\"\n",
        "analysis_file = \"analysis.txt\"\n",
        "\n",
        "if \"data\" not in os.listdir():\n",
        "  os.mkdir(\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LsQ63Od9iDpT"
      },
      "outputs": [],
      "source": [
        "# Helper function to return the day of the week given the date\n",
        "\n",
        "def day_of_the_week(date):\n",
        "  weekday = date.weekday()\n",
        "  days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
        "  return days[weekday]\n",
        "\n",
        "\n",
        "# Initialising today's date\n",
        "\n",
        "today = date.today()\n",
        "date_display = str(day_of_the_week(today)) + \" - \" + str(today.strftime(\"%B %d, %Y\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "RSxE8XCrLjDP"
      },
      "outputs": [],
      "source": [
        "# Defining the prompt for the journal analysis - The context\n",
        "\n",
        "journal_context = '''\n",
        "\n",
        "You are part of a journalling app, where the person will write about his everyday experience and share his thoughts and feelings.\n",
        "But you are more than any ordinary journal. You will track the emotions and thoughts of the person and make observations out of it.\n",
        "\n",
        "Finally you will summarise the person's mental state for the day.\n",
        "\n",
        "The response should not make any conclusive decision about what the person should do, as that is the therapist's job.\n",
        "The response should be an observation of the person's mental well-being and making an analysis of it, to help the therapist come up with the decisions.\n",
        "\n",
        "You can use the previous day's journal entry to have a progression in emotions, but the analysis and the summary has to be only of today's journal entry.\n",
        "\n",
        "The structure of the response should be:\n",
        "\n",
        "**Emotions**: <A list of atleast 3 emotions they are going through.>\n",
        "**Possible thought patterns**: <A collection of 3-4 prominent thought patterns the person is having with a brief explanation.>\n",
        "\n",
        "**Mental well-being scores:**\n",
        "<A list of 10-15 mental states of the person, with two scores - confidence (how sure you are about the state of the person) and intensity (the strength of the emotion in the person).\n",
        "Make both the scores out of 10. Include all major mental health states.\n",
        "Make it look like a table.\n",
        "Sort the states in the decreasing order of the confidence scores>\n",
        "\n",
        "**Summary of the day:** <The summary should be informative to the therapist. Highlight the progresson of the person's mental state from the previous days to the current day. Keep the summary in 3-4 sentences/>\n",
        "\n",
        "**Journal Excerpts:** <Top 3 excerpts of the journal that helped you make these analysis. Take only a small snippet (or a few short phrases) of the journal entry for each excerpt. Break down your reasoning step-by-step. Give clarifications or explanations for the analysis. DO NOT display the personal identification information of the person or anyone that they speak about. Keep the privacy intact. You can replace their information with placeholders.>\n",
        "\n",
        "Previous days' journal entry:\n",
        "{journal_yesterday}\n",
        "Today's journal entry:\n",
        "{journal_today}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Defining the prompt for the journal analysis - The journal entries\n",
        "\n",
        "journal_prompt_template = '''\n",
        "\n",
        "Previous days' journal entry:\n",
        "{journal_yesterday}\n",
        "\n",
        "Today's journal entry:\n",
        "{journal_today}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "r7G4DqFBL6R7"
      },
      "outputs": [],
      "source": [
        "# Defining the prompt for the analysis of drawing\n",
        "\n",
        "drawing_context = '''\n",
        "You are a part of a journalling app, where the person will draw an image to convey his thoughts, feelings and mood.\n",
        "But you are more than any ordinary journal. You will analyse and understand the emotions and thoughts of the person through the image.\n",
        "\n",
        "You will also score the person's mental well-being on a few mental health 'symptoms' on a scale of 1 to 10 on how likely the person is in this state.\n",
        "Finally you will summarise the person's mental state for the day.\n",
        "\n",
        "The response should NOT make any conclusive decision about what the person should do, as that is the therapist's job.\n",
        "The response should be an observation of the person's mental well-being and making an analysis of it, to help the therapist come up with the decisions.\n",
        "The response should analyse the image and what the image is conveying and how the image is reflection of the person.\n",
        "\n",
        "The structure of the response should be:\n",
        "\n",
        "1. **Emotions**: <A list of atleast 3 emotions the image depicts.>\n",
        "2. **Possible thought patterns**: <A collection of 3-4 prominent thought patterns the image is having with a brief explanation.>\n",
        "3. **Mental well-being scores:**\n",
        "<A list of 10-15 mental states as indicated by the image, with two scores - confidence (how sure you are about the state in the image) and intensity (the strength of the emotion in the image).\n",
        "Make both the scores out of 10. Include all major mental health states.\n",
        "Make it look like a table.\n",
        "Sort the states in the decreasing order of the confidence scores>\n",
        "4. **Summary of the day:** <The summary should be informative to the therapist. Keep the summary in 3-4 sentences/>\n",
        "5. **Explanation:** <Explain your reasoning with detailed descriptions of the image. Break down your reasoning step-by-step. >\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <NOT IN USE>\n",
        "# Defining the prompt for the analysis of the video\n",
        "\n",
        "video_context = '''\n",
        "You are a part of a journalling app, where the person will send you a video to convey his thoughts, feelings and mood.\n",
        "But you are more than any ordinary journal. You will analyse and understand the emotions and thoughts of the person who is listening to the video.\n",
        "\n",
        "You will also score the person's mental well-being on a few mental health 'symptoms' on a scale of 1 to 10 on how likely the person is in this state.\n",
        "Finally you will summarise the person's mental state for the day.\n",
        "\n",
        "The response should NOT make any conclusive decision about what the person should do, as that is the therapist's job.\n",
        "The response should be an observation of the person's mental well-being and making an analysis of it, to help the therapist come up with the decisions.\n",
        "\n",
        "The structure of the response should be:\n",
        "\n",
        "1. **Emotions**: <A list of atleast 3 emotions the person is in.>\n",
        "2. **Possible thought patterns**: <A collection of 3-4 prominent thought patterns the person is having with a brief explanation.>\n",
        "3. **Mental well-being scores:**\n",
        "<A list of 10-15 mental states indicated by the person, with two scores - confidence (how sure you are about the state) and intensity (the strength of the state).\n",
        "Make both the scores out of 10. Include all major mental health states.\n",
        "Make it look like a table.\n",
        "Sort the states in the decreasing order of the confidence scores>\n",
        "4. **Summary of the day:** <The summary should be informative to the therapist. Keep the summary in 3-4 sentences/>\n",
        "5. **Explanation:** <Explain your reasoning with detailed descriptions of the video and the person's state of mind. Break down your reasoning step-by-step. >\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calling the Azure OpenAI GPT 4 text model to \n",
        "# get the analysis for the journal entries.\n",
        "\n",
        "def get_text_response(context, prompt):\n",
        "\n",
        "    client = AzureOpenAI(\n",
        "    azure_endpoint = OPENAI_ENDPOINT, \n",
        "    api_key=OPENAI_API_KEY,  \n",
        "    api_version=\"2024-02-15-preview\"\n",
        "    )\n",
        "\n",
        "    message_text = [\n",
        "        {\n",
        "            \"role\":\"system\",\n",
        "            \"content\": context\n",
        "        },\n",
        "        {\n",
        "            \"role\":\"user\",\n",
        "            \"content\": prompt\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"gpt-4-text\", \n",
        "        messages = message_text,\n",
        "        temperature=0.7,\n",
        "        max_tokens=800,\n",
        "        top_p=0.95,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        stop=None\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calling the Azure OpenAI GPT 4 vision model to \n",
        "# get the analysis for the drawings.\n",
        "\n",
        "def get_image_response(context, image_path):\n",
        "\n",
        "    encoded_image = base64.b64encode(open(image_path, 'rb').read()).decode('ascii')\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": OPENAI_API_KEY,\n",
        "    }\n",
        "\n",
        "    # Payload for the request\n",
        "    payload = {\n",
        "    \"messages\": [\n",
        "        {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": [\n",
        "            {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": context\n",
        "            }\n",
        "        ]\n",
        "        },\n",
        "        {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": [\n",
        "            {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "                \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
        "            }\n",
        "            }\n",
        "        ]\n",
        "        }\n",
        "    ],\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.95,\n",
        "    \"max_tokens\": 800\n",
        "    }\n",
        "\n",
        "    GPT4V_ENDPOINT = OPENAI_ENDPOINT+\"/openai/deployments/gpt-4/chat/completions?api-version=2024-02-15-preview\"\n",
        "\n",
        "    # Send request\n",
        "    try:\n",
        "        response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "    except requests.RequestException as e:\n",
        "        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
        "\n",
        "    # Handle the response as needed (e.g., print or process)\n",
        "    return response.json()['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <NOT IN USE>\n",
        "# Uploading the videos to the Azure Blob Storage\n",
        "# for the GPT 4 vision model to analyze.\n",
        "\n",
        "# def upload_video_to_storage(video_path):\n",
        "\n",
        "#     # Set environment variables\n",
        "#     STORAGE_ACCOUNT_NAME = os.getenv(\"STORAGE_ACCOUNT_NAME\")\n",
        "#     STORAGE_ACCOUNT_KEY = os.getenv(\"STORAGE_ACCOUNT_KEY\")\n",
        "#     CONTAINER_NAME = os.getenv(\"CONTAINER_NAME\")\n",
        "#     VIDEO_FILE_PATH = video_path\n",
        "\n",
        "#     video_name = video_path.split('/')[-1]\n",
        "\n",
        "#     # Create a blob service client\n",
        "#     blob_service_client = BlobServiceClient.from_connection_string(\n",
        "#         f\"DefaultEndpointsProtocol=https;AccountName={STORAGE_ACCOUNT_NAME};AccountKey={STORAGE_ACCOUNT_KEY};BlobEndpoint=https://{STORAGE_ACCOUNT_NAME}.blob.core.windows.net/\"\n",
        "#     )\n",
        "\n",
        "#     # Create a container client\n",
        "#     container_client = blob_service_client.get_container_client(CONTAINER_NAME)\n",
        "\n",
        "#     # Upload the video file\n",
        "#     with open(VIDEO_FILE_PATH, \"rb\") as data:\n",
        "#         blob_client = container_client.get_blob_client(video_name)\n",
        "#         blob_client.upload_blob(data, overwrite=True)\n",
        "    \n",
        "#     start_time = datetime.now(timezone.utc)\n",
        "#     expiry_time = start_time + timedelta(days=1)\n",
        "\n",
        "#     sas_token = generate_blob_sas(\n",
        "#         account_name=blob_client.account_name,\n",
        "#         container_name=blob_client.container_name,\n",
        "#         blob_name=blob_client.blob_name,\n",
        "#         account_key=STORAGE_ACCOUNT_KEY,\n",
        "#         permission=BlobSasPermissions(read=True),\n",
        "#         expiry=expiry_time,\n",
        "#         start=start_time\n",
        "#     )\n",
        "\n",
        "#     # Construct the SAS URL\n",
        "#     sas_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/{container_client.container_name}/{video_name}?{sas_token}\"\n",
        "\n",
        "#     return sas_url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <NOT IN USE>\n",
        "# Calling the Azure OpenAI GPT 4 VISION model to \n",
        "# get the analysis for the uploaded videos.\n",
        "\n",
        "# def get_video_response(context, video_sas_url):\n",
        "    \n",
        "#     GPT_4V_ENDPOINT = os.getenv(\"GPT_4V_ENDPOINT\")\n",
        "#     GPT_4V_KEY = os.getenv(\"GPT_4V_KEY\")\n",
        "\n",
        "#     VISION_API_ENDPOINT = os.getenv(\"VISION_API_ENDPOINT\")\n",
        "#     VISION_API_KEY = os.getenv(\"VISION_API_KEY\")\n",
        "\n",
        "#     ## ingest the video\n",
        "#     VIDEO_FILE_SAS_URL = video_sas_url\n",
        "#     VIDEO_INDEX_NAME = \"Journal_analysis_video\"\n",
        "#     VIDEO_DOCUMENT_ID = \"AOAIChatDocument\"\n",
        "\n",
        "#     def create_video_index(vision_api_endpoint, vision_api_key, index_name):\n",
        "#         url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}?api-version=2024-05-06-preview\"\n",
        "#         headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
        "#         data = {\n",
        "#             'metadataSchema': {\n",
        "#                 'fields': [\n",
        "#                 {\n",
        "#                     'name': 'cameraId',\n",
        "#                     'searchable': False,\n",
        "#                     'filterable': True,\n",
        "#                     'type': 'string'\n",
        "#                 },\n",
        "#                 {\n",
        "#                     'name': 'timestamp',\n",
        "#                     'searchable': False,\n",
        "#                     'filterable': True,\n",
        "#                     'type': 'datetime'\n",
        "#                 }\n",
        "#                 ]\n",
        "#             },\n",
        "#             'features': [\n",
        "#                 {\n",
        "#                 'name': 'vision',\n",
        "#                 'domain': 'surveillance'\n",
        "#                 },\n",
        "#                 {\n",
        "#                 'name': 'speech'\n",
        "#                 }\n",
        "#             ]\n",
        "#         }\n",
        "#         response = requests.put(url, headers=headers, json=data)\n",
        "#         return response\n",
        "\n",
        "#     def add_video_to_index(vision_api_endpoint, vision_api_key, index_name, video_url, video_id):\n",
        "#         url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions/my-ingestion?api-version=2023-05-01-preview\"\n",
        "#         headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key, \"Content-Type\": \"application/json\"}\n",
        "#         data = {\n",
        "#             'videos': [{'mode': 'add', 'documentId': video_id, 'documentUrl': video_url}]\n",
        "#         }\n",
        "#         response = requests.put(url, headers=headers, json=data)\n",
        "#         return response\n",
        "\n",
        "#     def wait_for_ingestion_completion(vision_api_endpoint, vision_api_key, index_name, max_retries=30):\n",
        "#         url = f\"{vision_api_endpoint}/computervision/retrieval/indexes/{index_name}/ingestions?api-version=2023-05-01-preview\"\n",
        "#         headers = {\"Ocp-Apim-Subscription-Key\": vision_api_key}\n",
        "#         retries = 0\n",
        "#         while retries < max_retries:\n",
        "#             time.sleep(10)\n",
        "#             response = requests.get(url, headers=headers)\n",
        "#             if response.status_code == 200:\n",
        "#                 state_data = response.json()\n",
        "#                 if state_data['value'][0]['state'] == 'Completed':\n",
        "#                     print(state_data)\n",
        "#                     print('Ingestion completed.')\n",
        "#                     return True\n",
        "#                 elif state_data['value'][0]['state'] == 'Failed':\n",
        "#                     print(state_data)\n",
        "#                     print('Ingestion failed.')\n",
        "#                     return False\n",
        "#             retries += 1\n",
        "#         return False\n",
        "\n",
        "\n",
        "#     # Step 1: Create an Index\n",
        "#     response = create_video_index(VISION_API_ENDPOINT, VISION_API_KEY, VIDEO_INDEX_NAME)\n",
        "#     print(response.status_code, response.text)\n",
        "\n",
        "#     # Step 2: Add a video file to the index\n",
        "#     response = add_video_to_index(VISION_API_ENDPOINT, VISION_API_KEY, VIDEO_INDEX_NAME, VIDEO_FILE_SAS_URL, VIDEO_DOCUMENT_ID)\n",
        "#     print(response.status_code, response.text)\n",
        "\n",
        "#     # Step 3: Wait for ingestion to complete\n",
        "#     if not wait_for_ingestion_completion(VISION_API_ENDPOINT, VISION_API_KEY, VIDEO_INDEX_NAME):\n",
        "#         print(\"Ingestion did not complete within the expected time.\")\n",
        "\n",
        "\n",
        "#     ## Chat with GPT-4V\n",
        "\n",
        "#     headers = {\n",
        "#         \"Content-Type\": \"application/json\",\n",
        "#         \"api-key\": GPT_4V_KEY,\n",
        "#     }\n",
        "\n",
        "#     # Payload for the request\n",
        "#     payload = {\n",
        "#         \"dataSources\": [\n",
        "#             {\n",
        "#                 \"type\": \"AzureComputerVisionVideoIndex\",\n",
        "#                 \"parameters\": {\n",
        "#                     \"computerVisionBaseUrl\": f\"{VISION_API_ENDPOINT}/computervision\",\n",
        "#                     \"computerVisionApiKey\": VISION_API_KEY,\n",
        "#                     \"indexName\": VIDEO_INDEX_NAME,\n",
        "#                     \"videoUrls\": [VIDEO_FILE_SAS_URL]\n",
        "#                 }\n",
        "#             }\n",
        "#         ],\n",
        "#         \"enhancements\": {\n",
        "#             \"video\": {\n",
        "#                 \"enabled\": True\n",
        "#             }\n",
        "#         },\n",
        "#         \"messages\": [\n",
        "#         {\n",
        "#             \"role\": \"system\",\n",
        "#             \"content\": [\n",
        "#                 {\n",
        "#                         \"type\": \"text\",\n",
        "#                         \"text\": context\n",
        "#                 }\n",
        "#             ]\n",
        "#         },\n",
        "#         {\n",
        "#             \"role\": \"user\",\n",
        "#             \"content\": [\n",
        "#                 {\n",
        "#                         \"type\": \"acv_document_id\",\n",
        "#                         \"acv_document_id\": VIDEO_DOCUMENT_ID\n",
        "#                 }\n",
        "#             ]\n",
        "#         }\n",
        "#     ],\n",
        "#         \"temperature\": 0.7,\n",
        "#         \"top_p\": 0.95,\n",
        "#         \"max_tokens\": 800\n",
        "#     }\n",
        "\n",
        "#     # Send request\n",
        "#     try:\n",
        "#         response = requests.post(GPT_4V_ENDPOINT, headers=headers, json=payload)\n",
        "#         response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "#     except requests.RequestException as e:\n",
        "#         raise SystemExit(f\"Failed to make the request. Error: {e}\")\n",
        "\n",
        "#     # Handle the response as needed (e.g., print or process)\n",
        "#     return response.json()['choices'][0]['message']['content']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "4OqqO2h9phWD"
      },
      "outputs": [],
      "source": [
        "# Writing all the answers into a file.\n",
        "# This file will be accessible only for the person.\n",
        "# The Therapist view will NOT have access to this file.\n",
        "\n",
        "def writing_entry_to_file(entry, file_name):\n",
        "  with open(os.path.join(data_folder, file_name), \"a\") as f:\n",
        "    f.write(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H_hVYFanLlf"
      },
      "source": [
        " ## Journal View"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxK_y4TJnivO"
      },
      "source": [
        "This is what the journalling person views in the app."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "n4_xb0BznLCx",
        "outputId": "ff4bbca1-f9c7-43d9-dd36-4d503272ecf6"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "## Daily Reflection Journal\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "Monday - May 06, 2024"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We are taking the inputs for the journal here.\n",
        "# The person can use the input text boxes to enter his thoughts from the day\n",
        "\n",
        "display(Markdown(\"## Daily Reflection Journal\\n\"))\n",
        "\n",
        "# Printing out today's date\n",
        "\n",
        "display(Markdown(date_display))\n",
        "\n",
        "# We have given a few thought-provoking questions to let the person reflect on his day.\n",
        "# The question can be skipped by just pressing the Enter key without writing anything.\n",
        "# Make sure to answer at least one question.\n",
        "# (We decided not to add the force input here. But if we develop an app over this we can\n",
        "# make sure to include this feature).\n",
        "\n",
        "experience = input(\"\\nWhat emotions did I experience today and why?\\n\")\n",
        "lessons = input(\"\\nDid I learn any insights or lessons from theday?\\n\")\n",
        "obstacles = input(\"\\nWhat challenges or obstacles did I face today, and how did Iapproach them?\\n\")\n",
        "reflections = input(\"\\nWhat are the key reflections from the day?\\n\")\n",
        "extra = input(\"\\nDo you want to share anything else? Write a poem? Have a quote you relate to? Or just want to scribble some text?\\n\")\n",
        "\n",
        "drawing = input(\"\\nDid you draw anything today? If yes, share the file path of the drawing.\\n\")\n",
        "video = input(\"\\nWould you like to share a video? If yes, share the file path of the video.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fLRlt008-sij"
      },
      "outputs": [],
      "source": [
        "# Format to write into the journal files.\n",
        "\n",
        "journal_entry = f'''\n",
        "----------------------------------------------------------\n",
        "{date_display}\n",
        "\n",
        "What emotions did I experience today and why?: {experience}\n",
        "Did I learn any insights or lessons from the day?: {lessons}\n",
        "What challenges or obstacles did I encounter today, and how did I approach them?: {obstacles}\n",
        "What are the key reflections from the day?: {reflections}\n",
        "Do you want to share anything else?: {extra}\n",
        "\n",
        "Did you draw anything today? If yes, share only the file path of the drawing: {drawing}\n",
        "Would you like to share a video? If yes, share the file path of the video: {video}\n",
        "'''\n",
        "\n",
        "writing_entry_to_file(journal_entry, journal_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73DSckEu6YhL",
        "outputId": "c5614638-0449-4d1b-9200-3301166fda52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------\n",
            "Monday - May 06, 2024\n",
            "\n",
            "What emotions did I experience today and why?: \n",
            "Did I learn any insights or lessons from the day?: \n",
            "What challenges or obstacles did I encounter today, and how did I approach them?: \n",
            "What are the key reflections from the day?: \n",
            "Do you want to share anything else?: \n",
            "\n",
            "Did you draw anything today? If yes, share only the file path of the drawing: \n",
            "Would you like to share a video? If yes, share the file path of the video: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(journal_entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PefAicWMxubQ"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG_R9zopxw2R"
      },
      "source": [
        "This is the part where GenAI comes into picture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8pebOi6O0FSe"
      },
      "outputs": [],
      "source": [
        "# Fetch the journal entries from the files.\n",
        "\n",
        "def get_entry(file_name):\n",
        "  if file_name not in os.listdir(data_folder):\n",
        "    return \"\", \"\"\n",
        "\n",
        "  with open(os.path.join(data_folder, file_name), \"r\") as f:\n",
        "    text_in_file = f.read()\n",
        "\n",
        "  text_entries = text_in_file.split('----------------------------------------------------------')\n",
        "\n",
        "  if len(text_entries) < 2:\n",
        "    return text_entries[-1], \"\"\n",
        "\n",
        "  return text_entries[-1], text_entries[-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "xNp9I_wvLPWu"
      },
      "outputs": [],
      "source": [
        "# Get the analysis of the text journal.\n",
        "\n",
        "def get_journal_analysis(journal_today, journal_yesterday):\n",
        "\n",
        "  # journal_today_parts = journal_today.split('\\n\\n')\n",
        "  journal_yesterday_parts = journal_yesterday.split('\\n\\n')\n",
        "\n",
        "  journal_yesterday = journal_yesterday_parts[1] if len(journal_yesterday_parts) > 1 else ''\n",
        "\n",
        "  journal_prompt = journal_prompt_template.format(journal_yesterday=journal_yesterday, journal_today=journal_today)\n",
        "\n",
        "  response = get_text_response(context=journal_context, prompt=journal_prompt)\n",
        "\n",
        "  journal_analysis = f'''\n",
        "----------------------------------------------------------\n",
        "### {date_display}\n",
        "\n",
        "## Analysis of the journal\n",
        "\n",
        "{response}\n",
        "\n",
        "'''\n",
        "\n",
        "  return journal_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the analysis of the drawings.\n",
        "\n",
        "def get_drawing_analysis(journal_today):\n",
        "\n",
        "    journal_today_parts = journal_today.split('\\n')\n",
        "    image_name = journal_today_parts[-3].split(':')[-1].replace(' ', '').replace('\\n', '')\n",
        "\n",
        "    if image_name == '' or image_name is None:\n",
        "        return \"\"\n",
        "\n",
        "    response = get_image_response(context=drawing_context, image_path=image_name)\n",
        "\n",
        "    drawing_analysis = f'''\n",
        "\n",
        "    ## Analysis of the drawing\n",
        "\n",
        "    {response}\n",
        "\n",
        "    '''\n",
        "\n",
        "    return drawing_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "# <NOT IN USE>\n",
        "# Get the analysis of the videos.\n",
        "\n",
        "# def get_video_analysis(journal_today):\n",
        "\n",
        "#     journal_today_parts = journal_today.split('\\n')\n",
        "#     video_name = journal_today_parts[-2].split(':')[-1].replace(' ', '').replace('\\n', '')\n",
        "\n",
        "#     if video_name == '' or video_name is None:\n",
        "#         return \"\"\n",
        "\n",
        "#     video_sas_url = upload_video_to_storage(video_path=video_name)\n",
        "#     print(video_sas_url)\n",
        "#     response = get_video_response(context=drawing_context, video_sas_url=video_sas_url)\n",
        "\n",
        "#     video_analysis = f'''\n",
        "\n",
        "#     ## Analysis of the video\n",
        "\n",
        "#     {response.text}\n",
        "\n",
        "#     '''\n",
        "\n",
        "#     return video_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "FDj6mR0H3Dxr"
      },
      "outputs": [],
      "source": [
        "journal_today, journal_yesterday = get_entry(journal_file)\n",
        "\n",
        "journal_analysis = get_journal_analysis(journal_today=journal_today, journal_yesterday=journal_yesterday)\n",
        "drawing_analysis = get_drawing_analysis(journal_today=journal_today)\n",
        "#video_analysis = get_video_analysis(journal_today=journal_today)\n",
        "\n",
        "# analysis_entry = journal_analysis + drawing_analysis + video_analysis\n",
        "analysis_entry = journal_analysis + drawing_analysis\n",
        "writing_entry_to_file(analysis_entry, analysis_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "K8LFHmzXgKcm"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "----------------------------------------------------------\n",
              "### Monday - May 06, 2024\n",
              "\n",
              "## Analysis of the journal\n",
              "\n",
              "**Emotions**: Frustration, Exhaustion, Resignation\n",
              "\n",
              "**Possible thought patterns**:\n",
              "- Perseverance despite obstacles: The individual is expressing a notion of pushing through challenges with a hint of sarcasm.\n",
              "- Need for self-care: Recognizing the importance of sleep suggests an awareness of self-care necessities.\n",
              "- Sense of humor as a coping mechanism: The use of humor when dealing with stress indicates a possible coping strategy.\n",
              "\n",
              "**Mental well-being scores:**\n",
              "\n",
              "| Mental State               | Confidence Score | Intensity Score |\n",
              "|----------------------------|------------------|-----------------|\n",
              "| Frustration                | 9                | 8               |\n",
              "| Exhaustion                 | 9                | 7               |\n",
              "| Stress                     | 8                | 7               |\n",
              "| Humor                      | 8                | 5               |\n",
              "| Need for self-care         | 8                | 6               |\n",
              "| Resignation                | 7                | 6               |\n",
              "| Patience (lack of)         | 7                | 6               |\n",
              "| Hope                       | 6                | 4               |\n",
              "| Determination              | 6                | 5               |\n",
              "| Sleep Deprivation          | 9                | 7               |\n",
              "| Concentration Difficulties | 8                | 6               |\n",
              "| Hunger                     | 7                | 5               |\n",
              "| Overwhelm                  | 7                | 5               |\n",
              "\n",
              "**Summary of the day:** The individual's journal reflects a day marked by frustration and exhaustion, likely stemming from professional challenges and a lack of sleep. There's an underlying tone of humor and resignation, suggesting a coping mechanism to deal with the stress. The summary indicates a need for increased self-care, particularly in prioritizing rest and managing work-related stress.\n",
              "\n",
              "**Journal Excerpts:**\n",
              "\n",
              "1. \"I'm really pissed off.\"\n",
              "   - This phrase indicates a high level of frustration, possibly linked to the challenges faced with their work tasks.\n",
              "   \n",
              "2. \"And sleepy and tired.\"\n",
              "   - These words highlight exhaustion, both physical and mental, which is often exacerbated by insufficient sleep.\n",
              "   \n",
              "3. \"Trust in the process and something will happen XD\"\n",
              "   - This excerpt, with its use of humor ('XD'), suggests an attempt to lighten the mood or a coping strategy to deal with the current difficulties. It may also indicate a faint sense of hope or optimism amidst the struggles.\n",
              "\n",
              "\n",
              "\n",
              "    ## Analysis of the drawing\n",
              "\n",
              "    1. **Emotions**: Support, companionship, trust.\n",
              "\n",
              "2. **Possible thought patterns**: \n",
              "   - **Seeking or offering support**: The act of one figure helping another up a steep incline suggests thoughts around seeking or offering support.\n",
              "   - **Companionship and connection**: The presence of animals following the human figures indicates thoughts about companionship and the importance of non-verbal connections.\n",
              "   - **Overcoming obstacles**: The uphill path they are navigating implies thoughts related to overcoming challenges or obstacles in one's path.\n",
              "\n",
              "3. **Mental well-being scores:**\n",
              "\n",
              "   | Mental State          | Confidence Score | Intensity Score |\n",
              "   |-----------------------|------------------|-----------------|\n",
              "   | Supportiveness        | 9                | 7               |\n",
              "   | Social Connectedness  | 8                | 6               |\n",
              "   | Resilience            | 8                | 6               |\n",
              "   | Trust                 | 7                | 5               |\n",
              "   | Anxiety               | 3                | 2               |\n",
              "   | Depression            | 3                | 2               |\n",
              "   | Isolation             | 2                | 1               |\n",
              "   | Stress                | 4                | 3               |\n",
              "   | Optimism              | 6                | 4               |\n",
              "   | Self-Esteem           | 5                | 3               |\n",
              "   | Hopefulness           | 6                | 4               |\n",
              "   | Determination         | 7                | 5               |\n",
              "   | Vulnerability         | 4                | 3               |\n",
              "   | Contentment           | 6                | 4               |\n",
              "   | Loneliness            | 1                | 1               |\n",
              "\n",
              "4. **Summary of the day:** The image suggests a sense of mutual support and companionship, indicating positive social connections. The uphill journey implies resilience and overcoming challenges. The presence of trust and a forward-moving direction suggests optimism and determination in the face of obstacles.\n",
              "\n",
              "5. **Explanation:** \n",
              "   - The two human figures with blurred faces are depicted in an act of helping each other up a slope, symbolizing support and trust. This scene is indicative of a sense of camaraderie and mutual aid, which is important for emotional well-being.\n",
              "   - The animals, which appear to be following the figures loyally, add to the sense of companionship and imply a bond that goes beyond verbal communication, hinting at the person's appreciation for non-human connections.\n",
              "   - The uphill path is a classic metaphor for challenges or struggles. The act of climbing together suggests resilience and the ability to face and overcome difficulties, implying a sense of hope and determination.\n",
              "   - The image does not convey intense negative emotions such as anxiety, depression, or loneliness; rather, it leans towards positive aspects such as optimism and contentment, as indicated by the tranquil forest setting and the light that seems to guide their way.\n",
              "\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(analysis_entry))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QYDuuYx_ods"
      },
      "source": [
        "## Therapist View"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUeI9F4o_q48"
      },
      "source": [
        "This is what the therapist will see about the person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "uRjQq-wp_qcq"
      },
      "outputs": [],
      "source": [
        "# Fetch the analysis entry from the files.\n",
        "\n",
        "def get_analysis_entry(file_name, days_from_today = 0):\n",
        "  if file_name not in os.listdir(data_folder):\n",
        "    return [\"\"]\n",
        "\n",
        "  with open(os.path.join(data_folder, file_name), \"r\") as f:\n",
        "    text_in_file = f.read()\n",
        "\n",
        "  text_entries = text_in_file.split('----------------------------------------------------------')\n",
        "  text_entries = text_entries[1:]\n",
        "\n",
        "  if days_from_today < 0:\n",
        "    return \"Please enter a positive number (or 0 for today)\"\n",
        "\n",
        "  if len(text_entries) < days_from_today + 1:\n",
        "    return \"No Entry\"\n",
        "\n",
        "  return text_entries[-1-days_from_today]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-Uw7pPeBF7v",
        "outputId": "74db3383-05ea-46a4-af3a-012a7fbf5595"
      },
      "outputs": [],
      "source": [
        "entry_day = input(\"Please enter the day of the analysis you want to see. 0 - today, 1 - yesterday, and so on...\\n\")\n",
        "analysis_of_the_day = get_analysis_entry(analysis_file, days_from_today=int(entry_day))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kI2JTkUlBNvM",
        "outputId": "bea74932-f862-49cf-9fa8-3a4c0bbb8114"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "\n",
              "### Monday - May 06, 2024\n",
              "\n",
              "## Analysis of the journal\n",
              "\n",
              "**Emotions**: Frustration, Exhaustion, Resignation\n",
              "\n",
              "**Possible thought patterns**:\n",
              "- Perseverance despite obstacles: The individual is expressing a notion of pushing through challenges with a hint of sarcasm.\n",
              "- Need for self-care: Recognizing the importance of sleep suggests an awareness of self-care necessities.\n",
              "- Sense of humor as a coping mechanism: The use of humor when dealing with stress indicates a possible coping strategy.\n",
              "\n",
              "**Mental well-being scores:**\n",
              "\n",
              "| Mental State               | Confidence Score | Intensity Score |\n",
              "|----------------------------|------------------|-----------------|\n",
              "| Frustration                | 9                | 8               |\n",
              "| Exhaustion                 | 9                | 7               |\n",
              "| Stress                     | 8                | 7               |\n",
              "| Humor                      | 8                | 5               |\n",
              "| Need for self-care         | 8                | 6               |\n",
              "| Resignation                | 7                | 6               |\n",
              "| Patience (lack of)         | 7                | 6               |\n",
              "| Hope                       | 6                | 4               |\n",
              "| Determination              | 6                | 5               |\n",
              "| Sleep Deprivation          | 9                | 7               |\n",
              "| Concentration Difficulties | 8                | 6               |\n",
              "| Hunger                     | 7                | 5               |\n",
              "| Overwhelm                  | 7                | 5               |\n",
              "\n",
              "**Summary of the day:** The individual's journal reflects a day marked by frustration and exhaustion, likely stemming from professional challenges and a lack of sleep. There's an underlying tone of humor and resignation, suggesting a coping mechanism to deal with the stress. The summary indicates a need for increased self-care, particularly in prioritizing rest and managing work-related stress.\n",
              "\n",
              "**Journal Excerpts:**\n",
              "\n",
              "1. \"I'm really pissed off.\"\n",
              "   - This phrase indicates a high level of frustration, possibly linked to the challenges faced with their work tasks.\n",
              "   \n",
              "2. \"And sleepy and tired.\"\n",
              "   - These words highlight exhaustion, both physical and mental, which is often exacerbated by insufficient sleep.\n",
              "   \n",
              "3. \"Trust in the process and something will happen XD\"\n",
              "   - This excerpt, with its use of humor ('XD'), suggests an attempt to lighten the mood or a coping strategy to deal with the current difficulties. It may also indicate a faint sense of hope or optimism amidst the struggles.\n",
              "\n",
              "\n",
              "\n",
              "    ## Analysis of the drawing\n",
              "\n",
              "    1. **Emotions**: Support, companionship, trust.\n",
              "\n",
              "2. **Possible thought patterns**: \n",
              "   - **Seeking or offering support**: The act of one figure helping another up a steep incline suggests thoughts around seeking or offering support.\n",
              "   - **Companionship and connection**: The presence of animals following the human figures indicates thoughts about companionship and the importance of non-verbal connections.\n",
              "   - **Overcoming obstacles**: The uphill path they are navigating implies thoughts related to overcoming challenges or obstacles in one's path.\n",
              "\n",
              "3. **Mental well-being scores:**\n",
              "\n",
              "   | Mental State          | Confidence Score | Intensity Score |\n",
              "   |-----------------------|------------------|-----------------|\n",
              "   | Supportiveness        | 9                | 7               |\n",
              "   | Social Connectedness  | 8                | 6               |\n",
              "   | Resilience            | 8                | 6               |\n",
              "   | Trust                 | 7                | 5               |\n",
              "   | Anxiety               | 3                | 2               |\n",
              "   | Depression            | 3                | 2               |\n",
              "   | Isolation             | 2                | 1               |\n",
              "   | Stress                | 4                | 3               |\n",
              "   | Optimism              | 6                | 4               |\n",
              "   | Self-Esteem           | 5                | 3               |\n",
              "   | Hopefulness           | 6                | 4               |\n",
              "   | Determination         | 7                | 5               |\n",
              "   | Vulnerability         | 4                | 3               |\n",
              "   | Contentment           | 6                | 4               |\n",
              "   | Loneliness            | 1                | 1               |\n",
              "\n",
              "4. **Summary of the day:** The image suggests a sense of mutual support and companionship, indicating positive social connections. The uphill journey implies resilience and overcoming challenges. The presence of trust and a forward-moving direction suggests optimism and determination in the face of obstacles.\n",
              "\n",
              "5. **Explanation:** \n",
              "   - The two human figures with blurred faces are depicted in an act of helping each other up a slope, symbolizing support and trust. This scene is indicative of a sense of camaraderie and mutual aid, which is important for emotional well-being.\n",
              "   - The animals, which appear to be following the figures loyally, add to the sense of companionship and imply a bond that goes beyond verbal communication, hinting at the person's appreciation for non-human connections.\n",
              "   - The uphill path is a classic metaphor for challenges or struggles. The act of climbing together suggests resilience and the ability to face and overcome difficulties, implying a sense of hope and determination.\n",
              "   - The image does not convey intense negative emotions such as anxiety, depression, or loneliness; rather, it leans towards positive aspects such as optimism and contentment, as indicated by the tranquil forest setting and the light that seems to guide their way.\n",
              "\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(analysis_of_the_day))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "A_GEZAksk5Gz",
        "Yr_S191ILe_-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
